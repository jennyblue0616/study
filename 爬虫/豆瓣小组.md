---
author:于梦娇
---

## 豆瓣小组



```python
import json
import requests
from lxml import etree

# 获取图片
def get_resouce(url):
    headers = {
        "User-Agent": "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)"
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        # response.content字节流和text字符串拿到的都是加载js之前的源代码
        return response.content
    return None

# 获取页面
def page(url):

    headers = {
		"User-Agent": "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)"
	}
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.content.decode('utf-8')
    return None


# 解析页面
def parse(html):
    etree_html = etree.HTML(html)

    # title_result = etree_html.xpath('//div[@class="bd"]/h3/a/text()')
    # print(title_result)
    channel_result = etree_html.xpath('//div[@class="channel-item"]')
    list1 = []
    for item in channel_result:
        # 标题
        title = item.xpath('./div[@class="bd"]/h3/a/text()')[0]
        # 图片
        picture = item.xpath('./div[@class="bd"]/div[@class="block"]/div[@class="pic"]/div[@class="pic-wrap"]/img/@src')
        if len(picture) == 0:
            picture = ''
        else:
            picture = picture[0]

        # 文字
        text = item.xpath('./div[@class="bd"]/div[@class="block"]/p/text()')[0]
        # 小组
        group = item.xpath('./div[@class="bd"]/div[@class="source"]/span/a/text()')[0]
        # 时间
        time = item.xpath('./div[@class="bd"]/div[@class="source"]/span[@class="pubtime"]/text()')[0]
        # 喜欢个数
        likes = item.xpath('./div[@class="likes"]/text()[1]')[0]
        # 放列表
        dict={}
        dict['title'] = title
        dict['picture'] = picture
        dict['text'] = text
        dict['group'] = group
        dict['time'] = time
        dict['likes'] = likes
        list1.append(dict)
    return list1

# 所有网页
def get_all_pages():
    result_list=[]
    for i in range(10):
        page_num = 30 * i
        url = 'https://www.douban.com/group/explore?start='+str(page_num)
        html = page(url)
        one_list = parse(html)
        result_list.extend(one_list)
    return result_list


def save_json(result_list):
    json_text = json.dumps(result_list, ensure_ascii=False)
    with open('./douban.json', 'w', encoding='utf-8') as f:
        f.write(json_text)


def save_picture(result_list):
    for item in result_list:
        if item['picture']:
            picture_url = item['picture']
       
        p_name = picture_url.split('/')[-1]
        content = get_resouce(picture_url)
        with open('./d_images/%s'% p_name, 'wb') as f:
            f.write(content)


def main():
    result_list = get_all_pages()
    print(len(result_list))
    print(result_list)
    save_json(result_list)
 

if __name__ == '__main__':
        main()


```

数据库保存数据

```python
import json

import pymysql


def main():
    host = '127.0.0.1'
    port = 3306
    user = 'root'
    password = '123456'
    database = 'dj6'
    db = pymysql.connect(host, user, password, database, charset='utf8mb4', port=port)
    cursor = db.cursor()
    # print(cursor)

    with open('./douban.json', 'r', encoding='utf-8') as f:
        content = json.loads(f)

    # print(len(content))

    for i in range(len(content)):

        dict1 =content[i]
        title = dict1['title']
        picture = dict1['picture']
        text = dict1['text']
        group = dict1['group']
        time = dict1['time']
        likes = dict1['likes']

        # sql = f"insert into douban (title, picture, text, group, time, likes) values ('{title}', '{picture}', '{text}', '{group}', '{time}', '{likes}');"
        # print(title, picture, text, group, time, likes)
        sql = "insert into douban (title, picture, text, time, likes) values ('%s', '%s', '%s', '%s', '%s')" % (title, picture, text, time, likes)
        cursor.execute(sql)
        db.commit()


if __name__ == '__main__':
    main()


```

